{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20c0aa3c",
   "metadata": {},
   "source": [
    "\n",
    "### Clinical Note Classification using PEFT (LoRA), RoLA, and OpenAI Fine-Tuning\n",
    "\n",
    "This project fine-tunes three approaches for classifying clinical notes (e.g., identifying diseases like Type 1 or Type 2 diabetes) from a shared dataset `clinical_notes_large.csv`.\n",
    "\n",
    "#### Goals:\n",
    "- Compare **PEFT (LoRA)**, **RoLA**, and **OpenAI** fine-tuning pipelines\n",
    "- Use the same dataset and metrics for a fair comparison\n",
    "- Provide annotated code for reproducibility\n",
    "\n",
    "---\n",
    "\n",
    "#### Dataset: `clinical_notes_large.csv`\n",
    "\n",
    "- Contains synthetic clinical note texts and associated disease labels\n",
    "- Each method will load, preprocess, and use the same training and evaluation splits\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6e5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Env\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec101af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install peft transformers datasets accelerate\n",
    "# !pip install datasets\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11e922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d8531",
   "metadata": {},
   "source": [
    "### Step 1. Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152651ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before drop:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "Sample data:\n",
      "                                                 text              label\n",
      "0  Patient experienced chest pain and underwent E...  cardiac condition\n",
      "1  Adult-onset diabetes, family history positive,...    diabetes type 2\n",
      "2  Patient on ACE inhibitors for essential hypert...       hypertension\n",
      "3  Patient experienced chest pain and underwent E...  cardiac condition\n",
      "4  Early onset diabetes, C-peptide levels extreme...    diabetes type 1\n",
      "\n",
      "Label distribution:\n",
      " label\n",
      "hypertension         293\n",
      "diabetes type 1      290\n",
      "cardiac condition    262\n",
      "diabetes type 2      255\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"clinical_notes_large.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values before drop:\\n\", df[[\"text\", \"label\"]].isna().sum())\n",
    "\n",
    "# Drop rows with missing clinical text or label if exists\n",
    "df = df.dropna(subset=[\"text\", \"label\"])\n",
    "\n",
    "# Preview dataset\n",
    "print(\"Sample data:\\n\", df.head())\n",
    "\n",
    "# Optional: display label distribution\n",
    "print(\"\\nLabel distribution:\\n\", df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61229e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1cdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train-test split\n",
    "train_df, eval_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "# Save to disk for use in all pipelines\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "eval_df.to_csv(\"eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a10691e",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2: Fine-Tuning with PEFT (LoRA)\n",
    "\n",
    "Use Hugging Face's `peft` and `transformers` libraries to fine-tune a base model with LoRA. This is parameter-efficient and great for resource-limited environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbab44a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7095f955548748329526793590f3df56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907820426be84727b91c942af71e6d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Sealion\\anaconda3\\envs\\llms\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sealion\\AppData\\Local\\Temp\\ipykernel_8984\\2160267481.py:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  peft_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 03:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.542932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.052543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.022216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Hugging Face Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "\n",
    "# 4. Tokenization\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "eval_ds = eval_ds.map(tokenize, batched=True)\n",
    "\n",
    "train_ds = train_ds.remove_columns([\"text\"])\n",
    "eval_ds = eval_ds.remove_columns([\"text\"])\n",
    "\n",
    "# 5. PEFT with LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"],\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=len(df[\"label\"].unique())\n",
    ")\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "# 6. Training Setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "# 7. Trainer API\n",
    "peft_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 8. Train\n",
    "peft_trainer.train()\n",
    "\n",
    "# 9. Save label encoder\n",
    "import joblib\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5127278",
   "metadata": {},
   "source": [
    "### Step 3: Fine-Tuning with RoLA (Representation-Oriented Learning Alignment)\n",
    "\n",
    "This method aligns intermediate representations for robustness. Useful when generalization and structure-aware learning is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5adf0aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9e831b9f264d7d8a13ffb76ea3561f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1321d9307b1f47358c76f0fe7dc4663d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sealion\\anaconda3\\envs\\llms\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sealion\\AppData\\Local\\Temp\\ipykernel_8984\\1197877667.py:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `RoLALossTrainer.__init__`. Use `processing_class` instead.\n",
      "  rola_trainer = RoLALossTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 13:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.026407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.020353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.019489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=330, training_loss=0.07629402623032079, metrics={'train_runtime': 835.9185, 'train_samples_per_second': 3.158, 'train_steps_per_second': 0.395, 'total_flos': 694625659453440.0, 'train_loss': 0.07629402623032079, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# For the sake of placeholder, reuse Hugging Face trainer but annotate where RoLA logic can go.\n",
    "# RoLA Training for Clinical Note Classification with clinical_notes_large.csv\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Load and prepare data\n",
    "# df = pd.read_csv(\"clinical_notes_large.csv\")\n",
    "# df = df.dropna(subset=[\"text\", \"label\"])\n",
    "# df['label'] = pd.factorize(df['label'])[0]\n",
    "\n",
    "# train_df = df.sample(frac=0.8, random_state=42)\n",
    "# eval_df = df.drop(train_df.index)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "\n",
    "# Tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(df['label'].unique()))\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "eval_ds = eval_ds.map(tokenize, batched=True)\n",
    "\n",
    "\n",
    "# Custom RoLA-style loss Trainer\n",
    "\n",
    "class RoLALossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):  # Added **kwargs\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Use pooled output (or mean last hidden layer)\n",
    "        if hasattr(outputs, \"hidden_states\") and outputs.hidden_states:\n",
    "            # Use CLS token or pooled output for RoLA similarity\n",
    "            cls_embeddings = outputs.hidden_states[-1][:, 0, :]  # shape: (batch_size, hidden_size)\n",
    "        else:\n",
    "            raise ValueError(\"No hidden_states found in outputs. Enable `output_hidden_states=True`\")\n",
    "\n",
    "        # Cosine similarity matrix\n",
    "        cosine_sim = F.cosine_similarity(cls_embeddings.unsqueeze(1), cls_embeddings.unsqueeze(0), dim=-1)\n",
    "        target_sim = torch.eye(cls_embeddings.size(0)).to(cls_embeddings.device)\n",
    "        sim_loss = F.mse_loss(cosine_sim, target_sim)\n",
    "\n",
    "        ce_loss = F.cross_entropy(logits, inputs[\"labels\"])\n",
    "        total_loss = ce_loss + 0.2 * sim_loss  # Combine losses\n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./rola_output\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs_rola\",\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Train using RoLA-style loss\n",
    "rola_trainer = RoLALossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "rola_trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb042c41",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb6de1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee48249d3de48a68a125c502a39d0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===== PEFT/LoRA Evaluation =====\n",
      " Accuracy: 1.0000\n",
      " F1 Score (weighted): 1.0000\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        52\n",
      "           1       1.00      1.00      1.00        58\n",
      "           2       1.00      1.00      1.00        51\n",
      "           3       1.00      1.00      1.00        59\n",
      "\n",
      "    accuracy                           1.00       220\n",
      "   macro avg       1.00      1.00      1.00       220\n",
      "weighted avg       1.00      1.00      1.00       220\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Error during evaluation for RoLA: 'tuple' object has no attribute 'argmax'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "# Train/test split\n",
    "train_df, eval_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "\n",
    "# Convert eval set to Hugging Face Dataset\n",
    "eval_ds_raw = Dataset.from_pandas(eval_df.reset_index(drop=True))\n",
    "\n",
    "# Load tokenizer (must match the model you're using, e.g. BERT)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# Tokenize the evaluation dataset\n",
    "eval_ds = eval_ds_raw.map(tokenize, batched=True)\n",
    "eval_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "def evaluate_model(trainer, eval_dataset, model_name=\"\"):\n",
    "    try:\n",
    "        preds_output = trainer.predict(eval_dataset)\n",
    "\n",
    "        # Handle case where output is a tuple (e.g. custom RoLA Trainer)\n",
    "        if isinstance(preds_output, tuple):\n",
    "            predictions = preds_output[0]\n",
    "            labels = preds_output[1]\n",
    "        else:\n",
    "            predictions = preds_output.predictions\n",
    "            labels = preds_output.label_ids\n",
    "\n",
    "        preds = predictions.argmax(-1)\n",
    "        accuracy = accuracy_score(labels, preds)\n",
    "        f1 = f1_score(labels, preds, average='weighted')\n",
    "        report = classification_report(labels, preds)\n",
    "\n",
    "        print(f\"\\n ===== {model_name} Evaluation =====\")\n",
    "        print(f\" Accuracy: {accuracy:.4f}\")\n",
    "        print(f\" F1 Score (weighted): {f1:.4f}\")\n",
    "        print(\" Classification Report:\\n\", report)\n",
    "\n",
    "        return accuracy, f1, report\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error during evaluation for {model_name}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Evaluate PEFT/LoRA\n",
    "peft_acc, peft_f1, peft_report = evaluate_model(peft_trainer, eval_ds, model_name=\"PEFT/LoRA\")\n",
    "\n",
    "# Evaluate RoLA\n",
    "rola_acc, rola_f1, rola_report = evaluate_model(rola_trainer, eval_ds, model_name=\"RoLA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc24018",
   "metadata": {},
   "source": [
    "\n",
    "###  Step 4: Fine-Tuning with OpenAI GPT (External API)\n",
    "\n",
    "OpenAI fine-tuning works via uploading training files and running fine-tune jobs remotely.\n",
    "\n",
    "First, format the dataset to OpenAI's required `.jsonl` format with `{\"messages\": ..., \"completion\": ...}` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f637589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare Training JSONL\n",
    "import json\n",
    "openai_train = train_df.apply(lambda row: {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": row[\"text\"]}],\n",
    "    \"completion\": row[\"label\"]\n",
    "}, axis=1)\n",
    "\n",
    "with open(\"openai_train.jsonl\", \"w\") as f:\n",
    "    for line in openai_train:\n",
    "        f.write(json.dumps(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f3e1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize OpenAI Client\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "# load_dotenv(override=True)\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "\n",
    "# client = openai = OpenAI()\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47dcb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tune job submitted: ftjob-JSaCi3hM5eugXYrtwY0xlhA5\n",
      "Fine-tuned model ID (initial): None\n"
     ]
    }
   ],
   "source": [
    "# 3. Upload and Fine-tune\n",
    "train_file = client.files.create(file=open(\"openai_train.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    # model = \"gpt-4o-mini-2024-07-18\",\n",
    "    hyperparameters={\"n_epochs\": 3, \"batch_size\": 8}\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "fine_tuned_model_id = response.fine_tuned_model  # May be None if job not finished yet\n",
    "\n",
    "print(\"\\nFine-tune job submitted:\", job_id)\n",
    "print(\"Fine-tuned model ID (initial):\", fine_tuned_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a2bb3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: validating_files\n",
      "\n",
      " Training Log:\n",
      "1753889843: Validating training file: file-53rkwHm9EtRyVuWje1aHWx\n",
      "1753889843: Created fine-tuning job: ftjob-JSaCi3hM5eugXYrtwY0xlhA5\n",
      "\n",
      " Recent Jobs:\n",
      "ftjob-JSaCi3hM5eugXYrtwY0xlhA5 validating_files None\n",
      "ftjob-SBCME3bTn7KSgTsCnjQuTL14 failed None\n",
      "ftjob-OCsEjBKSq5NiUCFK3GBiECbF validating_files None\n",
      "ftjob-dJ13fHK43LQfbIhulKSpbwYG failed None\n",
      "ftjob-K07fp2c2Q2BuZUp4Vpbl7o6v failed None\n",
      "ftjob-qaq2PcDZ6u4z9EIHUWDkbIWR failed None\n",
      "ftjob-bEJ661Qv5Xq5rEjg9DnNQBuE failed None\n",
      "ftjob-celwDoTCMt9S1ZpHCLzLGJWE failed None\n",
      "ftjob-naiX5niE9wSQhdgL1wRbHMHi failed None\n",
      "ftjob-wA9xBTEqd7mvmMMUhQL3Z7RV failed None\n"
     ]
    }
   ],
   "source": [
    "# 4. Monitor Job \n",
    "job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "print(\"Status:\", job.status)\n",
    "\n",
    "print(\"\\n Training Log:\")\n",
    "for event in client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id):\n",
    "    print(f\"{event.created_at}: {event.message}\")\n",
    "\n",
    "print(\"\\n Recent Jobs:\")\n",
    "jobs = client.fine_tuning.jobs.list(limit=10)\n",
    "for j in jobs.data:\n",
    "    print(j.id, j.status, j.fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca0099b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save Test Set (Optional)\n",
    "openai_test = eval_df.apply(lambda row: {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": row[\"text\"]}\n",
    "    ],\n",
    "    \"completion\": row[\"label\"]\n",
    "}, axis=1)\n",
    "\n",
    "with open(\"openai_test.jsonl\", \"w\") as f:\n",
    "    for item in openai_test:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inference using Fine-Tuned Model \n",
    "# Replace this with your actual fine-tuned model ID\n",
    "model_id = \"ft:gpt-3.5-turbo-0613:<your-org>:<your-model-id>\"  # <-- UPDATE THIS with final model ID after job completes\n",
    "\n",
    "true_labels = eval_df[\"label\"].tolist()\n",
    "predicted_labels = []\n",
    "\n",
    "for prompt in tqdm(eval_df['text']):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a clinical note classifier. Return only the label.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    predicted = response.choices[0].message.content.strip()\n",
    "    predicted_labels.append(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f556225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluation \n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "print(\"\\n===== OpenAI GPT Fine-Tuned Model Evaluation =====\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\" F1 Score (weighted): {f1:.4f}\")\n",
    "print(\"\\n Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
